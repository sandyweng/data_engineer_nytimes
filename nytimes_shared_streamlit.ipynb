{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attractive-berlin",
   "metadata": {},
   "source": [
    "# Code for running topic modeling on the NY TIMES most shared articles on Facebook in the last 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outdoor-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import string\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import nltk\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "client = MongoClient()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database\n",
    "db = client.nytimes\n",
    "# collection\n",
    "shared = db.shared\n",
    "\n",
    "st.image('New-York-Times-Logo8x6_0.png.crdownload')\n",
    "\n",
    "st.title('Topic Modeling')\n",
    "num_topics = st.number_input('Number of Topics', min_value=1, max_value=200, value=10)\n",
    "\n",
    "seven_days_ago = datetime.today() - timedelta(days=6)\n",
    "seven_days_ago = seven_days_ago.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "tomorrow = datetime.today() + timedelta(days=1)\n",
    "tomorrow = tomorrow.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "extraction = list(shared.find({'updated': {'$lt': tomorrow, '$gte': seven_days_ago}}, {'_id': 0, 'abstract':1, 'published_date':1, 'title':1, 'adx_keywords':1, 'byline':1, 'section':1}))\n",
    "\n",
    "# function for transforming articles into dataframe and text preprocessing\n",
    "\n",
    "def transformation(extraction):\n",
    "    df = pd.DataFrame(extraction)\n",
    "    df=df.drop_duplicates(subset='abstract')\n",
    "    alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "    punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x.lower())\n",
    "    df['abstract'] = df.abstract.map(alphanumeric).map(punc_lower)\n",
    "    return df['abstract']\n",
    "\n",
    "clean_abstract = transformation(extraction)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "newStopWords = ['much', 'people', 'one', 'thing', 'always', 'every', 'everyone', 'yes', 'know', 'years', 'stop', 'let', 'need', \n",
    "               'something', 'find', 'others', 'enough', 'seems', 'often', 'never', 'still', 'like', 'say', 'hope', 'small', \n",
    "               'almost', 'take', 'important', 'said', 'turned', 'making', 'like', 'also', 'need', 'get', 'way', 'got', 'came', 'would',\n",
    "               'could']\n",
    "stopwords.extend(newStopWords)\n",
    "\n",
    "def tfidf(docs, stopwords):\n",
    "    tf = TfidfVectorizer(stop_words=stopwords)\n",
    "    word_matrix = tf.fit_transform(docs)\n",
    "    vocab = tf.get_feature_names()\n",
    "    return word_matrix, vocab\n",
    "\n",
    "word_matrix, vocab = tfidf(clean_abstract, stopwords)\n",
    "nmf=NMF(n_components=num_topics)\n",
    "fitted_nmf=nmf.fit(word_matrix)\n",
    "\n",
    "\n",
    "st.write('Topics of the Week')\n",
    "button = st.button('Analyze')\n",
    "if button:\n",
    "\ttopic_names=None\n",
    "\tfor ix, topic in enumerate(fitted_nmf.components_):\n",
    "\t\tif not topic_names or not topic_names[ix]:\n",
    "\t\t\tst.write(\"\\nTopic \", ix)\n",
    "\t\telse:\n",
    "\t\t\tst.write(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "\t\tst.write(\", \".join([vocab[i] for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-passenger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
